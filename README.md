 # ğŸ™ï¸ AI Lip-Sync Generator (Wav2Lip + Python Backend + Python Frontend + Colab GPU)

This project is a full working implementation of an **AI-powered lip-sync generation system** built as part of a technical assignment.

It accepts:

- **Image + Text** â†’ converts text â†’ audio â†’ lip-sync  
- **Image + Audio** â†’ directly lip-syncs the face  
- **Outputs:** A talking-face **video** synchronized to the audio

The heavy ML model **Wav2Lip** runs on **Google Colab GPU** (exposed via ngrok) due to the absence of a local GPU.  
The local machine runs:

- ğŸŸ¦ **FastAPI backend** (TTS + file handling + sending inference requests to Colab)  
- ğŸŸ© **Flask frontend** (simple UI for uploading image/text/audio)

Everything is written in **Python only**, end-to-end.

---

## ğŸš€ Architecture Overview

```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend     â”‚        â”‚            Backend            â”‚
â”‚  (Flask + HTML)â”‚  --->  â”‚    FastAPI (TTS + API)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  Calls Colab GPU for Wav2Lip  â”‚
â–²                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                   â”‚
â”‚                                   â–¼
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ Google Colab (GPU)     â”‚
                       â”‚ Wav2Lip Inference API  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

---

## âœ¨ Features

âœ” Upload an image + text â†’ auto-speech + lip sync  
âœ” Upload an image + audio â†’ direct lip sync  
âœ” Full Python Frontend (Flask)  
âœ” FastAPI backend with clean modular structure  
âœ” Google Colab GPU microservice for heavy Wav2Lip inference  
âœ” GTS Text-to-Speech integration  
âœ” Supports both MP4 and WAV inputs  
âœ” Auto video preview after generation  
âœ” Clean architecture suitable for production scaling  

---

## ğŸ—‚ Project Structure

```

wav2lip-project/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py             # FastAPI API endpoints
â”‚   â”‚   â”œâ”€â”€ colab_client.py     # Communication with Colab Wav2Lip server
â”‚   â”‚   â”œâ”€â”€ tts.py              # Text â†’ Speech (WAV)
â”‚   â”‚   â”œâ”€â”€ utils.py            # File saving helpers
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py                  # Flask frontend server
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html          # UI for uploads
â”‚   â””â”€â”€ static/                 # (optional)
â”‚
â””â”€â”€ colab/
â””â”€â”€ wav2lip_inference.ipynb # GPU runtime that acts like inference microservice

````

---

## ğŸ§© Technologies Used

- **Python 3.9+**
- **FastAPI** â€” backend REST API  
- **Flask** â€” frontend UI  
- **Wav2Lip** â€” lip-sync model  
- **Google Colab GPU** â€” for inference  
- **ngrok** â€” expose Colab as API endpoint  
- **gTTS + pydub** â€” text-to-speech  
- **requests** â€” backend â†’ Colab communication  

---

# âš™ï¸ Setup Instructions

## 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/wav2lip-project.git
cd wav2lip-project
````

---

## 2ï¸âƒ£ Start the Google Colab GPU Inference Server

1. Open the notebook:
   `colab/wav2lip_inference.ipynb`

2. Run cells in order:

   * Clone Wav2Lip
   * Install requirements
   * Load checkpoint
   * Start Flask + ngrok server

3. Copy the generated public URL, e.g.:

```
http://1234abcd.ngrok-free.app
```

4. Paste this URL into:

```
backend/app/colab_client.py
COLAB_URL = "<your-colab-url>/run-wav2lip"
```

---

## 3ï¸âƒ£ Install Backend Dependencies

```bash
cd backend
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8000
```

Backend will start on:

```
http://localhost:8000
```

---

## 4ï¸âƒ£ Start the Frontend

```bash
cd frontend
python app.py
```

Frontend will run on:

```
http://localhost:5000
```

---

# ğŸ§ª Usage

### **Generate Lip-Synced Video (Text)**

1. Open the frontend UI
2. Upload image
3. Enter text
4. Submit â†’ backend â†’ colab â†’ result video shown

### **Generate Lip-Synced Video (Audio)**

1. Upload image
2. Upload audio
3. Submit â†’ backend â†’ colab â†’ result video shown

---

# ğŸ“¡ API Documentation (Backend)

### **POST** `/generate-from-text`

```
Form-data:
  image: <image file>
  text: "Hello world"
Returns:
  video/mp4
```

### **POST** `/generate-from-audio`

```
Form-data:
  image: <image file>
  audio: <audio file>
Returns:
  video/mp4
```

---

# âœ”ï¸ Positive Findings (as required)

* Wav2Lip produces very accurate lip movements for frontal faces.
* Using Google Colab GPU removes hardware limitations.
* The architecture is modular and easy to extend.
* FastAPI + Flask combination kept everything Python-based.
* Easy to swap TTS or change inference engine.
* Clear separation of frontend, backend, and ML inference service.

---

# âŒ Negative Findings (as required)

* ngrok URL changes every session â†’ must update manually in backend.
* Colab disconnects after ~90 minutes â†’ temporary.
* GPU inference cannot be locally deployed without hardware.
* Quality reduces for non-frontal or low-light images.
* Some mouth-edge artifacts remain at certain frames.
* Latency increases if hosting Colab in free tier.

---

# ğŸ“ˆ Future Improvements

* Add video stabilizer
* Add face cropping / alignment
* Support multiple faces
* Use Coqui TTS for more natural emotion
* Deploy inference to a real GPU VM (AWS/GCP)
* Add queue system for multiple concurrent jobs
* Build React or Next.js frontend for professional UI

---

# ğŸ“ License

This project is for educational and assignment purposes.

---

# ğŸ™‹ About This Project

Built as part of an **AI + React/Python Technical Assignment** to demonstrate:

* ML model orchestration
* GPU offloading
* API development
* Clean software engineering

If you found it useful, please â­ the repo!

```
 
